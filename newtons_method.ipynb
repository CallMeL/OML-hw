{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CallMeL/OML-hw/blob/master/newtons_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc565ac7-a7cb-43aa-8e7b-7cd17901667f",
      "metadata": {
        "id": "bc565ac7-a7cb-43aa-8e7b-7cd17901667f"
      },
      "source": [
        "# Exercise sheet 5\n",
        "\n",
        "**Please turn in your exercises by Monday, December 9th.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e871567-aaa4-4bc9-809f-92536d8a061c",
      "metadata": {
        "id": "9e871567-aaa4-4bc9-809f-92536d8a061c"
      },
      "source": [
        "## Task 1: Newton's step\n",
        "\n",
        "Prove the following corollary.\n",
        "\n",
        "**Corollary**\n",
        "\n",
        "Let $f\\colon \\mathbb{R}^d \\to \\mathbb{R}$ be twice differentiable, $f \\in \\mathcal{S}_{\\mu,L}$ and $\\|\\nabla^2 f(x) - \\nabla^2 f(y)\\| \\leq M \\|x - y\\|$.\n",
        "\n",
        "If for some $t_0$ we have\n",
        "$$\n",
        "\\|x_{t_0} - x^\\star\\| \\leq \\frac{\\mu}{M}\n",
        "$$\n",
        "then $\\forall t > t_0$ we have\n",
        "$$\n",
        "\\|x_t - x^\\star\\|\\leq \\frac{\\mu}{2M} \\left(\\frac{1}{2}\\right)^{2^{t - t_0}}\n",
        "$$\n",
        "and\n",
        "$$\n",
        "f(x_t) - f(x^\\star) \\leq \\frac{L\\mu}{2M}\\left(\\frac{1}{2}\\right)^{2^{t - t_0}}\n",
        "$$\n",
        "**Proof**\n",
        "$$\n",
        "...\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55443425-346d-44f0-a68d-0c11611c5dc3",
      "metadata": {
        "id": "55443425-346d-44f0-a68d-0c11611c5dc3"
      },
      "source": [
        "## Task 2: Affine invariance\n",
        "\n",
        "Prove the following lemma.\n",
        "\n",
        "**Lemma**\n",
        "\n",
        "Let $f\\colon \\mathbb{R}^d \\to \\mathbb{R}$ be twice differentiable, $A \\in \\mathbb{R}^{d \\times d}$ an invertible matrix, $b \\in \\mathbb{R}^d$.\n",
        "Let $g\\colon \\mathbb{R}^d \\to \\mathbb{R}^d$ be the (bijective) function\n",
        "$$\n",
        "g(x) := Ax + b.\n",
        "$$\n",
        "Finally, for a twice differentiable function $h\\colon \\mathbb{R}^d \\to \\mathbb{R}$, let $N_h\\colon \\mathbb{R}^d \\to \\mathbb{R}^d$ denote the Newton step for $h$, i.e.\n",
        "$$\n",
        "N_h(x) := x - \\nabla^2 h(x)^{-1} \\nabla h(x),\n",
        "$$\n",
        "whenever this is definde. Then\n",
        "$$\n",
        "N_{f \\circ g} := g^{-1} \\circ N_f \\circ g.\n",
        "$$\n",
        "\n",
        "**Proof**\n",
        "$$\n",
        "...\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30880ba4-d7e9-4d49-b6d6-1d27e8001b70",
      "metadata": {
        "id": "30880ba4-d7e9-4d49-b6d6-1d27e8001b70"
      },
      "source": [
        "## Task 3: Non-quadratic convergence example\n",
        "\n",
        "Let $\\delta > 0$ be a real number. Find an example of a convex function $f \\colon \\mathbb{R} \\to \\mathbb{R}$ such that Newton's method satisfies\n",
        "$$\n",
        "|x_{t+1} - x^\\star| \\geq (1 - \\delta) |x_t + x^\\star|\n",
        "$$\n",
        "for all $x_t \\neq x^\\star$. For this function, Newton's method will not have a local quadratic convergence phase."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3884cb62-2014-43c0-8050-4c22cd19f75d",
      "metadata": {
        "id": "3884cb62-2014-43c0-8050-4c22cd19f75d"
      },
      "source": [
        "## Task 4: Babylonian method\n",
        "\n",
        "Prove that you need $O(\\log R)$ iterations to get $x_t - \\sqrt{R} < 1/2$ using the Babylonian method."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da85fa27-8181-408c-ac21-36e926dacd81",
      "metadata": {
        "id": "da85fa27-8181-408c-ac21-36e926dacd81"
      },
      "source": [
        "## Task 5: Positive definite bound\n",
        "\n",
        "Prove that $\\|Mx\\|_2 \\leq L\\|x\\|_2$ for all positive semidefinite $M$ with $L\\cdot \\mathbb{I} \\succeq M$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d31b735-7a43-48e7-895f-6ac3467931e7",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "5d31b735-7a43-48e7-895f-6ac3467931e7"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b3ab7ff-2090-4470-9bf5-6eff31c862a0",
      "metadata": {
        "id": "5b3ab7ff-2090-4470-9bf5-6eff31c862a0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0526ec1b-fb2c-4e29-8c47-a07b6609fb5d",
      "metadata": {
        "id": "0526ec1b-fb2c-4e29-8c47-a07b6609fb5d"
      },
      "outputs": [],
      "source": [
        "def contour_map(f, xb=(-1,1), yb=(-1,1), ax=None):\n",
        "    if ax is None:\n",
        "        ax = plt\n",
        "    (nx, ny) = (45, 45)\n",
        "    x = np.linspace(*xb, nx)\n",
        "    y = np.linspace(*yb, ny)\n",
        "    xv, yv = np.meshgrid(x, y)\n",
        "    X = np.block([ [xv.reshape(1, -1)], [yv.reshape(1, -1)] ]).T\n",
        "    zv = np.fromiter((f(x) for x in X), dtype=np.double)\n",
        "    zv = zv.reshape(nx,ny)\n",
        "    ax.contour(xv, yv, zv, 15)\n",
        "\n",
        "def surface_plot(f, xb=(-1,1), yb=(-1,1)):\n",
        "    (nx, ny) = (45, 45)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    x = np.linspace(*xb, nx)\n",
        "    y = np.linspace(*yb, ny)\n",
        "    xv, yv = np.meshgrid(x, y)\n",
        "    X = np.block([ [xv.reshape(1, -1)], [yv.reshape(1, -1)] ]).T\n",
        "    zv = np.fromiter((f(x) for x in X), dtype=np.double)\n",
        "    zv = zv.reshape(nx,ny)\n",
        "    ax.plot_surface(xv, yv, zv, cmap=cm.coolwarm)\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4139b34-74b0-4c7b-8094-9fe78ede4fa3",
      "metadata": {
        "id": "f4139b34-74b0-4c7b-8094-9fe78ede4fa3"
      },
      "outputs": [],
      "source": [
        "def backtracking_line_search(x, d, f, g, alpha=0.3, beta=0.8):\n",
        "    step_size = 1.\n",
        "    while f(x + step_size * d) > f(x) + alpha * step_size * g(x).dot(d):\n",
        "        step_size *= beta\n",
        "    return step_size\n",
        "\n",
        "def backtracking_line_search_nag(x, d, f, g, alpha=1., beta=0.8):\n",
        "    t = 1\n",
        "    while f(x + t*d) > f(x) + alpha * t * np.dot(g(x), d) + t/2*np.dot(d, d):\n",
        "        t *= beta\n",
        "    return t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f0355c-8e11-435a-b4f6-5c4253fd95ee",
      "metadata": {
        "id": "a3f0355c-8e11-435a-b4f6-5c4253fd95ee"
      },
      "outputs": [],
      "source": [
        "def gradient_descent_path(x0, f, g, max_iter=100):\n",
        "    xs = [x0]\n",
        "    for _ in range(max_iter):\n",
        "        step = backtracking_line_search(x0, -g(x0), f, g)\n",
        "        x0 = x0 - step * g(x0)\n",
        "        xs.append(x0)\n",
        "    return xs\n",
        "\n",
        "def heavy_ball_path(x0, f, g, max_iter=100):\n",
        "    xs = [x0]\n",
        "    x_old = x0\n",
        "    for i in range(1, max_iter+1):\n",
        "        d = -g(x0) + (i-1)/(i+1) *  (x0-x_old)\n",
        "        x_old = x0\n",
        "        t = backtracking_line_search_nag(x0, d, f, g)\n",
        "        x0 = x0 + t * d\n",
        "        xs.append(x0)\n",
        "    return xs\n",
        "\n",
        "def nag_path(x0, f, g, max_iter=100):\n",
        "    xs = [x0]\n",
        "    x_old = x0\n",
        "    for i in range(1, max_iter+1, 1):\n",
        "        y = x0 + (i-1)/(i+2) *  (x0-x_old)\n",
        "        x_old = x0\n",
        "        t = backtracking_line_search_nag(y, -g(y), f, g)\n",
        "        x0 = y - t * g(y)\n",
        "        xs.append(x0)\n",
        "    return np.array(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5816f59c-9dba-4f72-a144-271e5152046c",
      "metadata": {
        "id": "5816f59c-9dba-4f72-a144-271e5152046c"
      },
      "outputs": [],
      "source": [
        "EXA = np.array([[30., 15],[-20, 25]])/20\n",
        "\n",
        "EXAMPLES = [\n",
        "    (lambda x: x.T@EXA@x + 1, lambda x: (EXA+EXA.T)@x, lambda x: (EXA+EXA.T), 0.5 * np.ones(2), (-1.,1.), (-1.,1.)),\n",
        "    (lambda x: (x[0]**2 + 30 * x[1]**2 + 4 * x[0]), lambda x: np.array([2 * x[0] + 4, 60 * x[1]]), lambda x: np.array([[2, 0],[0, 60]]), np.array([2.,3.]), (-2.5,2.5), (-1.5,3.5)),\n",
        "    (lambda x: np.linalg.norm(np.sin(x*3))**2, lambda x: 6 * np.sin(x*3) * np.cos(x*3), lambda x: 18 * np.diag(2 * np.cos(3*x)**2 - 1), np.array([.2,.15]), (-.5, .5), (-.5,.5))\n",
        "]\n",
        "\n",
        "def run_examples_newtons_method():\n",
        "    for (f, g, h, x0, xb, yb) in EXAMPLES:\n",
        "        xs2 = newtons_method_path(x0, f, g, h)\n",
        "        xs2 = np.array(xs2)\n",
        "\n",
        "        xs = gradient_descent_path(x0, f, g)\n",
        "        xs = np.array(xs)\n",
        "\n",
        "        contour_map(f, xb=xb, yb=yb)\n",
        "        plt.plot(xs2[:,0], xs2[:,1], '.--k', label='newtons method')\n",
        "        plt.plot(xs[:,0], xs[:,1], '.--', color='gray', alpha=.5, label='gradient descent')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc3173a-453d-48fa-b0c0-8fddb861481c",
      "metadata": {
        "id": "1dc3173a-453d-48fa-b0c0-8fddb861481c"
      },
      "source": [
        "## Task 6: Newton's method\n",
        "\n",
        "Implement Newton's method using the above provided backtracking line search.\n",
        "* `x0` is the initial point.\n",
        "* `f` is the function you are trying to minimize.\n",
        "* `g` is the gradient of `f`.\n",
        "* `h` is the hessian of `f`.\n",
        "\n",
        "Function `newtons_method_path` should return a list of vectors on the path to the minimum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe6a515-7830-4816-8a43-c216f8b4294b",
      "metadata": {
        "id": "cfe6a515-7830-4816-8a43-c216f8b4294b"
      },
      "outputs": [],
      "source": [
        "def newtons_method_path(x0, f, g, h, max_iter=100):\n",
        "    return ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87802424-9573-4cea-9db8-1a3317ab5ea1",
      "metadata": {
        "id": "87802424-9573-4cea-9db8-1a3317ab5ea1"
      },
      "outputs": [],
      "source": [
        "# run this to get plots\n",
        "run_examples_newtons_method()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a81a9ce0-1a09-45e0-953e-6836a52c8474",
      "metadata": {
        "id": "a81a9ce0-1a09-45e0-953e-6836a52c8474"
      },
      "source": [
        "## Task 7: Error plots\n",
        "\n",
        "Complete the hessians of the following functions.\n",
        "Then compare and plot the error over time for the four methods on the following tasks.\n",
        "Implementations of the prior methods are given in the Utils section."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b032adb-e1c2-4d0f-a258-d0ba56ee3e28",
      "metadata": {
        "id": "2b032adb-e1c2-4d0f-a258-d0ba56ee3e28"
      },
      "source": [
        "### Simple quadratic function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "952d75b4-4dca-41eb-b2ac-55144aa0126c",
      "metadata": {
        "id": "952d75b4-4dca-41eb-b2ac-55144aa0126c"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    return x[0]**2 + 30 * x[1]**2 + 4 * x[0]\n",
        "def g(x):\n",
        "    return np.array([2 * x[0] + 4, 60 * x[1]])\n",
        "def h(x):\n",
        "    return ...\n",
        "\n",
        "x0 = np.array([2.,3.])\n",
        "\n",
        "x_star = np.array([-2.,0.])\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "510aa632-0b89-449f-a81b-5d38eec3e2be",
      "metadata": {
        "id": "510aa632-0b89-449f-a81b-5d38eec3e2be"
      },
      "source": [
        "### Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e9e1b6-a8e4-42f8-80c2-2661b099f92d",
      "metadata": {
        "id": "d4e9e1b6-a8e4-42f8-80c2-2661b099f92d"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "def f(w):\n",
        "    return np.linalg.norm(X @ w - y) ** 2 / len(X)\n",
        "\n",
        "def g(w):\n",
        "    return 2 * X.T @ (X @ w - y) / len(X)\n",
        "\n",
        "def h(w):\n",
        "    return ...\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=100, n_informative=40, random_state=0)\n",
        "x0 = np.zeros(100)\n",
        "\n",
        "x_star = np.linalg.lstsq(X, y, rcond=None)[0]\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0104abd0-5728-4b25-ada7-3c574379f339",
      "metadata": {
        "id": "0104abd0-5728-4b25-ada7-3c574379f339"
      },
      "source": [
        "### Logistic regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dacc5fb-e053-4704-9634-ffe60ee42186",
      "metadata": {
        "id": "5dacc5fb-e053-4704-9634-ffe60ee42186"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def f(w):\n",
        "    return np.log(1. + np.exp(-y * X.dot(w))).mean() + np.linalg.norm(w)**2\n",
        "\n",
        "def g(w):\n",
        "    sig = np.exp(-y * X.dot(w))\n",
        "    return 2*w - X.T.dot(sig * y / (sig + 1.)) / X.shape[0]\n",
        "\n",
        "def h(w):\n",
        "    return ...\n",
        "\n",
        "X, y = make_classification(1000, 80, n_informative=40,\n",
        "#                               n_redundant=0,\n",
        "                               n_clusters_per_class=2, flip_y=0.1, random_state=0)\n",
        "\n",
        "x0 = np.zeros(80)\n",
        "x_star = minimize(f, x0, jac=g).x\n",
        "..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}